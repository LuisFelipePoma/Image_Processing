{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7tsCI7mxqR6",
        "outputId": "3788cfbd-5b04-4d2f-cc6e-7b2e3a3cdef4"
      },
      "outputs": [],
      "source": [
        "!pip install -U matplotlib\n",
        "!pip install tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLeDxfij2408"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import time\n",
        "import matplotlib.pyplot as plt### plotting bar chart\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.layers import (Reshape, Conv2DTranspose, Add, Conv2D, MaxPool2D, Dense,\n",
        "                                     Flatten, InputLayer, BatchNormalization, Input, MultiHeadAttention)\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow_addons as tfa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiHKk5vAlO4k"
      },
      "source": [
        "# Data Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4Z2MAGzeT9s",
        "outputId": "16b06d5c-79ad-4fde-b4e3-8cd610a8a472"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d jessicali9530/celeba-dataset\n",
        "!unzip \"/content/celeba-dataset.zip\" -d \"/content/dataset/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIwphbWzmOSg"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRp4-Y5Wzcag"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2TFHNrTwTYC"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "TIME_STEPS = 1000\n",
        "IM_SHAPE = (64,64,3)\n",
        "N_HEADS = 8\n",
        "ATTN_DIM = 256\n",
        "N_GROUPS = 8\n",
        "N_RESNETS = 2\n",
        "LEARNING_RATE = 2e-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeK2xa4TpGgx",
        "outputId": "de362962-d8b1-40c3-8599-7cff703f8bd2"
      },
      "outputs": [],
      "source": [
        "ds_train = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"/content/dataset/img_align_celeba/img_align_celeba\", label_mode=None, image_size=(IM_SHAPE[0], IM_SHAPE[1]), batch_size=32\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IW9lsYqFmQJh"
      },
      "outputs": [],
      "source": [
        "def preprocess(image):\n",
        "  return tf.cast(image, tf.float32) / 127.5 - 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLe2w8Yp1P6b"
      },
      "outputs": [],
      "source": [
        "def augmentation(image):\n",
        "  return ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2O2svt-mQMI",
        "outputId": "5dbf8ebe-93df-43ef-88a6-c23e300c1737"
      },
      "outputs": [],
      "source": [
        "train_dataset = (\n",
        "    ds_train\n",
        "    .map(preprocess)\n",
        "    .unbatch()\n",
        "    .shuffle(buffer_size = 1024, reshuffle_each_iteration = True)\n",
        "    .batch(BATCH_SIZE,drop_remainder=True)\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "\n",
        "for d in train_dataset.take(1):\n",
        "  print(d.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ic6__qNvw-9p"
      },
      "source": [
        "## Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "N_TeeVu7xBaD",
        "outputId": "7db4b9bb-7d0a-404e-f7cc-c4576ccede92"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (4,4))\n",
        "k=0\n",
        "n = 4\n",
        "for i in range(n):\n",
        "    ax = plt.subplot(2,2, k+1)\n",
        "    plt.imshow((d[i]+1)/2)\n",
        "    plt.axis(\"off\")\n",
        "    k+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYW2f-vmxBce"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtQBa6ElzmrL"
      },
      "source": [
        "## Dataset Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHWK04_KzpHg"
      },
      "outputs": [],
      "source": [
        "def linear_beta_schedule(timesteps):\n",
        "    beta_start = 0.0001\n",
        "    beta_end = 0.02\n",
        "    return tf.linspace(beta_start, beta_end, timesteps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKHoU83Hzjgg"
      },
      "outputs": [],
      "source": [
        "# define beta schedule\n",
        "betas = linear_beta_schedule(TIME_STEPS)\n",
        "\n",
        "# define alphas\n",
        "alphas = 1. - betas\n",
        "alphas_cumprod = tf.math.cumprod(alphas, axis=0)\n",
        "alphas_cumprod_prev = tf.concat([tf.ones((1,)),alphas_cumprod[:-1]],axis = 0)\n",
        "sqrt_recip_alphas = tf.math.sqrt(1.0 / alphas)\n",
        "\n",
        "# calculations for diffusion q(x_t | x_{t-1}) and others\n",
        "sqrt_alphas_cumprod = tf.math.sqrt(alphas_cumprod)\n",
        "sqrt_one_minus_alphas_cumprod = tf.math.sqrt(1. - alphas_cumprod)\n",
        "\n",
        "# calculations for posterior q(x_{t-1} | x_t, x_0)\n",
        "posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02dCiCcV0G-W"
      },
      "outputs": [],
      "source": [
        "def extract(a, t, x_shape):\n",
        "  b, *_ = t.shape\n",
        "  out = tf.gather(a,t)\n",
        "  output = tf.reshape(out, (b,*((1,) * (len(x_shape) - 1))))\n",
        "  return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csEmNrqe0HAw"
      },
      "outputs": [],
      "source": [
        "def q_sample(x_start, t, noise):\n",
        "\n",
        "  sqrt_alphas_cumprod_t = extract(sqrt_alphas_cumprod, t, x_start.shape)\n",
        "  sqrt_one_minus_alphas_cumprod_t = extract(\n",
        "      sqrt_one_minus_alphas_cumprod, t, x_start.shape\n",
        "  )\n",
        "  out_sample = sqrt_alphas_cumprod_t * x_start + sqrt_one_minus_alphas_cumprod_t * noise\n",
        "  return out_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JXUSFeu0nw0",
        "outputId": "d44a3573-ccb7-4fb1-d221-54e4db0e5e92"
      },
      "outputs": [],
      "source": [
        "x_start = d\n",
        "\n",
        "t = tf.random.uniform((BATCH_SIZE,),minval=0,maxval=TIME_STEPS, dtype=tf.int32)\n",
        "print(t)\n",
        "print(x_start.shape, t.shape, )\n",
        "sample = q_sample(x_start, t,tf.random.normal(x_start.shape))\n",
        "print(sample.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "7doUxfmx0nzN",
        "outputId": "52b12fb1-6951-4550-c719-3ae1d45b1463"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (4,4))\n",
        "k=0\n",
        "n = 4\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(2,2, k+1)\n",
        "  plt.imshow((sample[i]+1)/2)\n",
        "  plt.axis(\"off\")\n",
        "  k+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ztt9ODe30n12"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVSxlz01BhVu"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57QGLl0vB_jL"
      },
      "source": [
        "## Positional Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhAnfC_F0n4r"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbeddings(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.embedding_dim = dim\n",
        "\n",
        "    def get_timestep_embedding(self, timesteps, embedding_dim: int):\n",
        "        \"\"\"\n",
        "        From Fairseq.\n",
        "        Build sinusoidal embeddings.\n",
        "        This matches the implementation in tensor2tensor, but differs slightly\n",
        "        from the description in Section 3.5 of \"Attention Is All You Need\".\n",
        "        \"\"\"\n",
        "        half_dim = self.embedding_dim // 2\n",
        "        emb = tf.math.log(10000.) / (half_dim - 1)\n",
        "        emb = tf.exp(tf.range(half_dim, dtype=tf.float32) * -emb)\n",
        "        emb = tf.cast(timesteps, dtype = tf.float32)[:, None] * emb[None, :]\n",
        "        emb = tf.concat([tf.sin(emb), tf.cos(emb)], axis=1)\n",
        "        if embedding_dim % 2 == 1:\n",
        "            emb = tf.pad(emb, [[0, 0], [0, 1]])\n",
        "        return emb\n",
        "\n",
        "    def call(self, time):\n",
        "        return self.get_timestep_embedding(time, self.embedding_dim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7y1KeAHB9Za"
      },
      "source": [
        "## Residual Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4ncG132BzhW"
      },
      "outputs": [],
      "source": [
        "def res_block(x,filters,n_groups,temb):\n",
        "    previous = x\n",
        "    x = Conv2D(filters, 3, padding=\"same\",)(x) ### Convolution layer with padding same, so that the resolution remains the same\n",
        "\n",
        "    ### temb represents the time embedding.\n",
        "    ### It is passed into the silu activation function and a Dense Layer(Which can change the the embedding dimension )\n",
        "    ### We also reshape the time embedding to match the output of 2d convnets.\n",
        "    x += Dense(filters)(tf.nn.silu(temb))[:,None,None,:]\n",
        "\n",
        "    ### Group Normalization is used.\n",
        "    x = tf.nn.silu(tfa.layers.GroupNormalization(n_groups, axis = -1)(x))\n",
        "    x = Conv2D(filters, 3, padding=\"same\",)(x)\n",
        "\n",
        "    # Project residual\n",
        "    residual = Conv2D(filters, 1,padding=\"same\",)(previous)\n",
        "    x = tf.keras.layers.add([x, residual])  # Add back residual\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZ5gQmKjB7HM"
      },
      "source": [
        "## Unet Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cMusL4UBzjx"
      },
      "outputs": [],
      "source": [
        "def get_model(im_shape=(64,64,3),n_resnets=2,n_groups=8,attn_dim=32,n_heads=4,):\n",
        "    input_1 = Input(shape=im_shape)### image input\n",
        "    input_2 = Input(shape=())### time input\n",
        "    t_dim = im_shape[0]*16\n",
        "\n",
        "    # Entry block\n",
        "    x = Conv2D(32, 3, padding=\"same\")(input_1)\n",
        "    temb = PositionalEmbeddings(t_dim)(input_2)### Create embeddings from the time input_2\n",
        "    temb = Dense(t_dim)(tf.nn.gelu(Dense(t_dim)(temb)))### pass the embedding into the gelu activation function\n",
        "\n",
        "    hs = [x]### variable used for storing each resolution level output, in the downward path, to be concatenated to the inputs of the upward path.\n",
        "\n",
        "    ### Downward Path\n",
        "    for filters in [32, 64, 128, 256]:### for every resolution level (32,64,128,256), represent the depth they map to resolutions of (32,16,8,4)\n",
        "        for _ in range(n_resnets):### we go through each resnet block per resolution level\n",
        "            x = res_block(x,filters,n_groups,temb)### resblock\n",
        "            ### if the resolution=16 (coinciding with a depth=64), we make the resnet output features attend to each other.\n",
        "            ### Note how the attention axes = (1,2). This corresponds to the height and width dimensions.\n",
        "            ### Feel free to Check the documentation out :) https://www.tensorflow.org/api_docs/python/tf/keras/layers/MultiHeadAttention.\n",
        "            ### query = key = value = x.\n",
        "            ### We again use Group Normalization.\n",
        "            if filters == 64:\n",
        "                x = tfa.layers.GroupNormalization(groups=n_groups, axis = -1)(\n",
        "                    MultiHeadAttention(num_heads=n_heads, key_dim=attn_dim, attention_axes=(1,2), )(query = x, value = x))\n",
        "        hs.append(x)### append the output features to hs\n",
        "        x = tf.keras.layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)### Downsampling in order to move to the next resolution level\n",
        "\n",
        "\n",
        "    ### Bottleneck\n",
        "    x = res_block(x,256,n_groups,temb)\n",
        "    x = tfa.layers.GroupNormalization(groups=n_groups, axis = -1)(\n",
        "      MultiHeadAttention(num_heads=n_heads, key_dim=attn_dim, attention_axes=(1,2), )(query = x, value = x))\n",
        "    x = res_block(x,256,n_groups,temb)\n",
        "\n",
        "\n",
        "    ### Upward path\n",
        "    for filters in [256, 128, 64,32]:\n",
        "        ### we resize x, to match with the shape of feature outputs (hs) in the downward path\n",
        "        x = tf.image.resize_with_pad(x,hs[-1].shape[1],hs[-1].shape[2])\n",
        "        x = tf.concat([x,hs.pop()], axis=-1)\n",
        "\n",
        "        for _ in range(n_resnets):\n",
        "            x = res_block(x,filters,n_groups,temb)\n",
        "\n",
        "            if filters == 64:\n",
        "                x = tfa.layers.GroupNormalization(groups=n_groups, axis = -1)(\n",
        "                  MultiHeadAttention(num_heads=n_heads, key_dim=attn_dim, attention_axes=(1,2), )(query = x, value = x))\n",
        "\n",
        "        if filters != 32:\n",
        "            x = Conv2DTranspose(filters, 3, strides = (2,2),)(x)### Upsampling\n",
        "\n",
        "    x = res_block(x,32,n_groups,temb)\n",
        "    outputs = Conv2D(3, 3, padding=\"same\", )(x)\n",
        "\n",
        "    # Define the model\n",
        "    model = Model([input_1,input_2], outputs,name='unet')\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1PoPmjXBznV",
        "outputId": "0d4c0108-2505-438a-f105-c446d40f103f"
      },
      "outputs": [],
      "source": [
        "# Build model\n",
        "model= get_model(im_shape=IM_SHAPE,n_resnets=N_RESNETS,n_groups=N_GROUPS,attn_dim=ATTN_DIM,n_heads=N_HEADS,)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-WnACfDsO2J",
        "outputId": "a79f7ff7-3f01-4063-bf1b-db727a15b6d9"
      },
      "outputs": [],
      "source": [
        "model.load_weights('/content/drive/MyDrive/Bang/unet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJ8AGMYnEV_K"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oR86y1eQBzrP"
      },
      "outputs": [],
      "source": [
        "OPTIMIZER = Adam(learning_rate = 0.5e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yw80zs81Egnu"
      },
      "outputs": [],
      "source": [
        "def custom_loss(denoise_model, x_start, t, noise=None):\n",
        "  h = tf.keras.losses.Huber()\n",
        "  noise = tf.random.normal(x_start.shape,mean=0,stddev=1)\n",
        "  x_noisy = q_sample(x_start,t,noise)\n",
        "\n",
        "  predicted_noise = denoise_model([x_noisy, t])\n",
        "\n",
        "  # plt.figure(figsize = (10,10))\n",
        "  # outs = [x_noisy,noise,predicted_noise]\n",
        "  # print('predicted------------',predicted_noise)\n",
        "  # print('actual -------------;',noise)\n",
        "  # for i in range(3):\n",
        "  #   ax = plt.subplot(1,3, i+1)\n",
        "  #   plt.imshow(outs[i][10])\n",
        "  #   plt.axis(\"off\")\n",
        "\n",
        "  return h(noise,predicted_noise)#tf.reduce_mean(tf.math.square(noise-predicted_noise))#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bohlDLykEgqH"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def training_block(x_batch):\n",
        "  with tf.GradientTape() as recorder:\n",
        "\n",
        "    t = tf.random.uniform((BATCH_SIZE,),minval=0,maxval=TIME_STEPS,dtype=tf.int32)\n",
        "    loss = custom_loss(model,x_batch,t)\n",
        "\n",
        "  partial_derivatives = recorder.gradient(loss, model.trainable_weights)\n",
        "  OPTIMIZER.apply_gradients(zip(partial_derivatives, model.trainable_weights))\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNlgWRK0Eqvq"
      },
      "outputs": [],
      "source": [
        "def neuralearn(EPOCHS):\n",
        "  for epoch in range(EPOCHS):\n",
        "    init_time = time.time()\n",
        "    losses = []\n",
        "    for step, x_batch in enumerate(train_dataset):\n",
        "      loss = training_block(x_batch)\n",
        "      losses.append(loss)\n",
        "      if step%500==0:\n",
        "        print(step)\n",
        "\n",
        "    print(str(epoch+1)+\"/\"+str(EPOCHS)+\": Training Loss----->\", sum(losses)/len(losses))\n",
        "    print('Time Elapsed: ---> '+str(time.time()-init_time)+' s')\n",
        "    model.save('/content/drive/MyDrive/Bang/unet')\n",
        "\n",
        "  print(\"Training Complete!!!!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SuLIBuqEEqyE",
        "outputId": "0c133927-dea3-49a2-f781-d983c6a0a36c"
      },
      "outputs": [],
      "source": [
        "neuralearn(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-YHVGo4nxuK"
      },
      "source": [
        "# Testing :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FR9QXeNmn2x8"
      },
      "outputs": [],
      "source": [
        "#@tf.function\n",
        "def p_sample(model, x, t, t_index):\n",
        "\n",
        "  betas_t = extract(betas, t, x.shape)\n",
        "  sqrt_one_minus_alphas_cumprod_t = extract(sqrt_one_minus_alphas_cumprod, t, x.shape)\n",
        "  sqrt_recip_alphas_t = extract(sqrt_recip_alphas, t, x.shape)\n",
        "\n",
        "  model_mean = sqrt_recip_alphas_t * (x - betas_t * model([x, t]) / sqrt_one_minus_alphas_cumprod_t)\n",
        "\n",
        "  if t_index == 0:\n",
        "      return model_mean\n",
        "  else:\n",
        "      posterior_variance_t = extract(posterior_variance, t, x.shape)\n",
        "      noise = tf.random.normal(x.shape)\n",
        "\n",
        "      # Algorithm 2 line 4:\n",
        "      return model_mean + tf.math.sqrt(posterior_variance_t) * noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1WJozu8itEy",
        "outputId": "ead0529c-8da0-467a-d508-fd1f8b7fde9b"
      },
      "outputs": [],
      "source": [
        "\n",
        "imgs = []\n",
        "img = tf.random.normal((64,IM_SHAPE[0],IM_SHAPE[1],IM_SHAPE[2]))\n",
        "for i in reversed(range(0, TIME_STEPS)):\n",
        "  print(i)\n",
        "  img = p_sample(model,img,tf.fill((1,),i,), i)\n",
        "  imgs.append(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 926
        },
        "id": "6vWH9DYdazzs",
        "outputId": "c75388db-2c29-4b54-fcee-08606c772c95"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (12,12))\n",
        "\n",
        "for i in range(16):\n",
        "  ax = plt.subplot(4,4, i+1)\n",
        "  plt.imshow((np.array(imgs[999])[16+i]+1)/2)\n",
        "  plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fqZeiR3QoYYX",
        "outputId": "3dd57c8e-a2b5-4935-a0a2-ae155cdcc31f"
      },
      "outputs": [],
      "source": [
        "import matplotlib.animation as animation\n",
        "\n",
        "random_index = 3\n",
        "\n",
        "fig = plt.figure()\n",
        "ims = []\n",
        "for i in range(TIME_STEPS):\n",
        "    im = plt.imshow(np.array(imgs[i])[random_index], animated=True)\n",
        "    ims.append([im])\n",
        "\n",
        "animate = animation.ArtistAnimation(fig, ims, interval=5, blit=True, repeat_delay=1000)\n",
        "animate.save('diffusion.gif')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ed3NhyPoYah",
        "outputId": "842b9d8a-8c46-43ec-8f5e-62d879978208"
      },
      "outputs": [],
      "source": [
        "len(ims)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqigSU1qxufy"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5uZjRsjO1qo"
      },
      "outputs": [],
      "source": [
        "\n",
        "class PositionalEmbeddings(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, dim):\n",
        "    super().__init__()\n",
        "    self.embedding_dim = dim\n",
        "\n",
        "  def get_timestep_embedding(self, timesteps, embedding_dim: int):\n",
        "    \"\"\"\n",
        "    From Fairseq.\n",
        "    Build sinusoidal embeddings.\n",
        "    This matches the implementation in tensor2tensor, but differs slightly\n",
        "    from the description in Section 3.5 of \"Attention Is All You Need\".\n",
        "    \"\"\"\n",
        "    half_dim = self.embedding_dim // 2\n",
        "    emb = tf.math.log(10000.) / (half_dim - 1)\n",
        "    emb = tf.exp(tf.range(half_dim, dtype=tf.float32) * -emb)\n",
        "    emb = tf.cast(timesteps, dtype = tf.float32)[:, None] * emb[None, :]\n",
        "    emb = tf.concat([tf.sin(emb), tf.cos(emb)], axis=1)\n",
        "    # if embedding_dim % 2 == 1:\n",
        "    #   emb = tf.pad(emb, [[0, 0], [0, 1]])\n",
        "    return emb\n",
        "\n",
        "  def call(self, time):\n",
        "\n",
        "    return self.get_timestep_embedding(time, self.embedding_dim)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5Qu_5LaQWlu",
        "outputId": "e9393fb2-6423-4c30-f5a5-3713ed5c858f"
      },
      "outputs": [],
      "source": [
        "\n",
        "timesteps = 200\n",
        "t = tf.random.uniform((BATCH_SIZE,), 0, timesteps, dtype = tf.int32 )\n",
        "\n",
        "pos = PositionalEmbeddings(256)\n",
        "print(pos(t))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ilVl1ViGL35"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SABFtsKKoRDk"
      },
      "source": [
        "## Convert TO GIF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8skFWIboUbu"
      },
      "outputs": [],
      "source": [
        "import matplotlib.animation as animation\n",
        "\n",
        "random_index = 7\n",
        "\n",
        "fig = plt.figure()\n",
        "ims = []\n",
        "for i in range(timesteps):\n",
        "    im = plt.imshow(np.array(imgs[i])[random_index][...,0], cmap=\"gray\", animated=True)\n",
        "    ims.append([im])\n",
        "\n",
        "animate = animation.ArtistAnimation(fig, ims, interval=50, blit=True, repeat_delay=1000)\n",
        "animate.save('diffusion.gif')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "emN9bGyjPyDu"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
