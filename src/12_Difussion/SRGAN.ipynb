{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGcCsOilc8b1"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.layers import (Reshape,LeakyReLU,Dropout,Conv2DTranspose, Add, Conv2D, MaxPool2D, Dense,\n",
        "                                     Flatten, InputLayer, BatchNormalization, Input,GlobalAvgPool2D,PReLU )\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPLHB2s5gBJu"
      },
      "source": [
        "# Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Plya5Y4OeOPl",
        "outputId": "6944421a-9c6a-4734-eda5-1510c38d01cf"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d badasstechie/celebahq-resized-256x256\n",
        "!unzip \"/content/celebahq-resized-256x256.zip\" -d \"/content/dataset/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ni3A9hDmgKKU"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "IM_SHAPE = (64,64,3)\n",
        "B=24\n",
        "LEARNING_RATE = 1e-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9_RtczneOSH",
        "outputId": "28accf2a-183c-4dd8-df04-d3b924fd8c45"
      },
      "outputs": [],
      "source": [
        "ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"/content/dataset/celeba_hq_256\", label_mode=None, image_size=(IM_SHAPE[0], IM_SHAPE[1]), batch_size=BATCH_SIZE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZjG7N8geOU_"
      },
      "outputs": [],
      "source": [
        "def preprocess(image):\n",
        "  return tf.image.resize(image,[IM_SHAPE[0]//4,IM_SHAPE[1]//4],method='bicubic')/255,tf.cast(image,tf.float32)/127.5 - 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2lAK49h977P",
        "outputId": "1e4c9652-e6fc-4d70-8c8b-35df1a225a9b"
      },
      "outputs": [],
      "source": [
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JBWJWy0e-G9"
      },
      "outputs": [],
      "source": [
        "train_dataset = (\n",
        "    ds.take(12000)\n",
        "    .map(preprocess)\n",
        "    .unbatch()\n",
        "    .shuffle(buffer_size = 1024, reshuffle_each_iteration = True)\n",
        "    .batch(BATCH_SIZE,drop_remainder=True)\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bssNU2hc0eo3",
        "outputId": "ef7d3d18-471e-40a4-c1b0-e6dd42708a62"
      },
      "outputs": [],
      "source": [
        "for d1,d2 in train_dataset.take(1):\n",
        "  print(d1.shape,d2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        },
        "id": "5AhVXUnre-O1",
        "outputId": "10753a03-7a77-479a-98aa-c643bbb1104a"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (8,8))\n",
        "k=0\n",
        "n = 6\n",
        "for i in range(n):\n",
        "    ax = plt.subplot(3,2, k+1)\n",
        "    if i<2:\n",
        "      plt.imshow(d1[i])\n",
        "    elif i>=2 and i<4:\n",
        "      plt.imshow(cv2.resize(np.array(d1[i-2]),(64,64)))\n",
        "    else:\n",
        "      plt.imshow((d2[i-4]+1)/2)\n",
        "    plt.axis(\"off\")\n",
        "    k+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdtWfpUGgC4E"
      },
      "source": [
        "# MOdeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPzQhU4cJvmd"
      },
      "outputs": [],
      "source": [
        "class ResBlock(Layer):\n",
        "    def __init__(self,n_filters,filter_size,strides,name='res_block'):\n",
        "      super(ResBlock, self).__init__(name=name)\n",
        "      self.n_filters=n_filters\n",
        "      self.filter_size=filter_size\n",
        "      self.strides=strides\n",
        "\n",
        "    def build(self,input_shape):\n",
        "      self.conv_1=Conv2D(\n",
        "          self.n_filters,self.filter_size,strides=self.strides,padding='same')\n",
        "      self.batch_norm_1=BatchNormalization()\n",
        "      self.prelu=PReLU()\n",
        "      self.conv_2=Conv2D(\n",
        "          self.n_filters,self.filter_size,strides=self.strides,padding='same')\n",
        "      self.batch_norm_2=BatchNormalization()\n",
        "\n",
        "    def call(self,x_in):\n",
        "      x=self.conv_1(x_in)\n",
        "      x=self.prelu(self.batch_norm_1(x))\n",
        "      x=self.conv_2(x)\n",
        "      x=self.batch_norm_2(x)\n",
        "      return x+x_in"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DElSXYFLCaS"
      },
      "outputs": [],
      "source": [
        "class UpsampleBlock(Layer):\n",
        "    def __init__(self,n_filters,filter_size,strides,name='upsample_block'):\n",
        "      super(UpsampleBlock, self).__init__(name=name)\n",
        "      self.n_filters=n_filters\n",
        "      self.filter_size=filter_size\n",
        "      self.strides=strides\n",
        "\n",
        "    def build(self,input_shape):\n",
        "      self.conv=Conv2D(\n",
        "          self.n_filters,self.filter_size,strides=self.strides,padding='same')\n",
        "      self.prelu=PReLU()\n",
        "    def call(self,x):\n",
        "      x=self.conv(x)\n",
        "      x=tf.nn.depth_to_space(x, 2)\n",
        "      x=self.prelu(x)\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpxObeQNe-RF",
        "outputId": "2e2c5bac-ba2d-4332-f59d-85bd6cd64b7d"
      },
      "outputs": [],
      "source": [
        "input_lr=tf.keras.layers.Input(shape=(IM_SHAPE[0]//4,IM_SHAPE[1]//4,3))\n",
        "input_conv=tf.keras.layers.Conv2D(64,9,1,padding='same')(input_lr)\n",
        "input_conv=PReLU()(input_conv)\n",
        "\n",
        "x=input_conv\n",
        "for i in range(B):\n",
        "  x=ResBlock(64,3,1,name='res_block_'+str(i))(x)\n",
        "\n",
        "x=tf.keras.layers.Conv2D(64,9,padding='same')(x)\n",
        "x=tf.keras.layers.BatchNormalization()(x)\n",
        "\n",
        "x+=input_conv\n",
        "\n",
        "x=UpsampleBlock(256,3,1,name='upsample_block_1')(x)\n",
        "x=UpsampleBlock(256,3,1,name='upsample_block_2')(x)\n",
        "\n",
        "output_sr=tf.keras.layers.Conv2D(3,9,activation='tanh',padding='same')(x)\n",
        "\n",
        "srresnet=tf.keras.models.Model(input_lr,output_sr)\n",
        "srresnet.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0iZbRVkySUs6"
      },
      "outputs": [],
      "source": [
        "class ConvBlock(Layer):\n",
        "    def __init__(self,n_filters,filter_size,strides,name='conv_block'):\n",
        "      super(ConvBlock, self).__init__(name=name)\n",
        "      self.n_filters=n_filters\n",
        "      self.filter_size=filter_size\n",
        "      self.strides=strides\n",
        "\n",
        "    def build(self,input_shape):\n",
        "      self.conv=Conv2D(\n",
        "          self.n_filters,self.filter_size,strides=self.strides,padding='same')\n",
        "      self.batch_norm=BatchNormalization()\n",
        "\n",
        "    def call(self,x):\n",
        "      x=self.conv(x)\n",
        "      x=LeakyReLU()(self.batch_norm(x))\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIgbRN3ie-Tc",
        "outputId": "38dcc44f-539e-4fbb-dc34-3386da5a8c3c"
      },
      "outputs": [],
      "source": [
        "input_lr=tf.keras.layers.Input(shape=(IM_SHAPE[0],IM_SHAPE[1],3))\n",
        "input_conv=tf.keras.layers.Conv2D(64,3,padding='same')(input_lr)\n",
        "input_conv=tf.keras.layers.LeakyReLU()(input_conv)\n",
        "\n",
        "channel_nums=[64,128,128,256,256,512,512]\n",
        "stride_sizes=[2,1,2,1,2,1,2]\n",
        "\n",
        "disc=input_conv\n",
        "for i in range(7):\n",
        "  disc=ConvBlock(\n",
        "      channel_nums[i],3,stride_sizes[i],name='conv_block_'+str(i))(disc)\n",
        "disc = GlobalAvgPool2D()(disc)\n",
        "disc=tf.keras.layers.Dense(1024)(disc)\n",
        "disc=tf.keras.layers.LeakyReLU()(disc)\n",
        "\n",
        "disc_output=tf.keras.layers.Dense(1,activation='sigmoid')(disc)\n",
        "\n",
        "discriminator=tf.keras.models.Model(input_lr,disc_output)\n",
        "discriminator.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tktFYE07vrjR"
      },
      "outputs": [],
      "source": [
        "def pixel_MSE(y_true,y_pred):\n",
        "  return tf.reduce_mean( (y_true - y_pred) ** 2 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9KnfnbEp0Ak",
        "outputId": "bb12b074-0fb9-4db7-e143-d7f1e23d7a0d"
      },
      "outputs": [],
      "source": [
        "VGG19=tf.keras.applications.VGG19(weights='imagenet',include_top=False,input_shape=(256,256,3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wa6-iNREtpAQ"
      },
      "outputs": [],
      "source": [
        "def VGG_loss(y_hr,y_sr,i_m=2,j_m=2):\n",
        "  i,j=0,0\n",
        "  accumulated_loss=0.0\n",
        "  for l in VGG19.layers:\n",
        "    cl_name=l.__class__.__name__\n",
        "    if cl_name=='Conv2D':\n",
        "      j+=1\n",
        "    if cl_name=='MaxPooling2D':\n",
        "      i+=1\n",
        "      j=0\n",
        "    if i==i_m and j==j_m:\n",
        "      break\n",
        "\n",
        "    y_hr=l(y_hr)\n",
        "    y_sr=l(y_sr)\n",
        "    if cl_name=='Conv2D':\n",
        "      mse=tf.keras.losses.MeanSquaredError(name='mean_squared_error')\n",
        "      accumulated_loss+=mse(y_hr,y_sr)*0.006\n",
        "\n",
        "  return accumulated_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzgVRF5lzbuK"
      },
      "outputs": [],
      "source": [
        "def content_loss(y_true,y_pred):\n",
        "  mse=tf.keras.losses.MeanSquaredError(name='mean_squared_error')\n",
        "  return mse(y_true,y_pred)+VGG_loss(y_true,y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EX8x_kl6fLWh"
      },
      "outputs": [],
      "source": [
        "class GANMonitor(tf.keras.callbacks.Callback):\n",
        "\n",
        "  def on_epoch_end(self, epoch,logs=None):\n",
        "    plt.figure(figsize = (16,16))\n",
        "    k=0\n",
        "    n = 6\n",
        "    for i in range(n):\n",
        "      ax = plt.subplot(3,2, k+1)\n",
        "      if i<2:\n",
        "        plt.imshow(d1[i])\n",
        "      elif i>=2 and i<4:\n",
        "        out=self.model.generator(tf.expand_dims(d1[i-2],axis=0))\n",
        "        plt.imshow((out[0]+1)/2)\n",
        "      else:\n",
        "        plt.imshow((d2[i-4]+1)/2)\n",
        "      plt.axis(\"off\")\n",
        "      k+=1\n",
        "\n",
        "    plt.savefig(\"generated/gen_images_epoch_{}.png\".format(epoch+1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-FukMaRe-XN"
      },
      "outputs": [],
      "source": [
        "class SRGAN(tf.keras.Model):\n",
        "    def __init__(self, discriminator, generator):\n",
        "        super(SRGAN, self).__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, loss_disc,loss_gen,):\n",
        "        super(SRGAN, self).compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.loss_disc=loss_disc\n",
        "        self.loss_gen=loss_gen\n",
        "        self.d_loss_metric = tf.keras.metrics.Mean(name=\"d_loss\")\n",
        "        self.g_loss_metric = tf.keras.metrics.Mean(name=\"g_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.d_loss_metric, self.g_loss_metric]\n",
        "\n",
        "    def train_step(self, real_images):\n",
        "\n",
        "      lr_images,hr_images = real_images\n",
        "\n",
        "      batch_size = tf.shape(hr_images)[0]\n",
        "\n",
        "      generated_images = self.generator(lr_images)\n",
        "\n",
        "      real_labels = tf.ones((batch_size, 1))\n",
        "      fake_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "      # Train the discriminator\n",
        "      with tf.GradientTape() as tape:\n",
        "\n",
        "          real_predictions = self.discriminator(hr_images)\n",
        "          d_loss_real = self.loss_disc(real_labels,real_predictions)\n",
        "\n",
        "          fake_predictions = self.discriminator(generated_images)\n",
        "          d_loss_fake = self.loss_disc(fake_labels,fake_predictions)\n",
        "\n",
        "          d_loss = 0.5*(d_loss_fake+d_loss_real)\n",
        "      grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "      self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n",
        "\n",
        "      misleading_labels = tf.ones((batch_size, 1))\n",
        "\n",
        "      with tf.GradientTape() as tape:\n",
        "          predictions = self.generator(lr_images)\n",
        "          g_loss = self.loss_gen(hr_images, predictions)\n",
        "          g_loss=g_loss+1e-3*self.loss_disc(misleading_labels, self.discriminator(predictions))\n",
        "\n",
        "      grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "      self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "      # Update metrics\n",
        "      self.d_loss_metric.update_state(d_loss)\n",
        "      self.g_loss_metric.update_state(g_loss)\n",
        "      return {\n",
        "          \"d_loss\": self.d_loss_metric.result(),\n",
        "          \"g_loss\": self.g_loss_metric.result(),\n",
        "      }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5p4XGOGfLYv"
      },
      "outputs": [],
      "source": [
        "epochs = 36\n",
        "\n",
        "gan = SRGAN(discriminator=discriminator, generator=srresnet, )\n",
        "gan.compile(\n",
        "    d_optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE,beta_1=0.5),\n",
        "    g_optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE,beta_1=0.5),\n",
        "    loss_disc=tf.keras.losses.BinaryCrossentropy(),\n",
        "    loss_gen=content_loss,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_yTHWqAraFfm"
      },
      "outputs": [],
      "source": [
        "!mkdir generated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ae7A6uuN7NUj",
        "outputId": "0d2cda84-a5e2-4677-d46e-2d4e53ddd16d"
      },
      "outputs": [],
      "source": [
        "history=gan.fit(\n",
        "    train_dataset, epochs=epochs, callbacks=[GANMonitor()]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X57mSI-y7NWw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LnaEZmXc7NnU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkT-Wpjc7NpT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESmFW_Hm7Ntg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ox8Zo5OH7Nv8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6OdeIf07NyQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9w7O6d11COm"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "gPLHB2s5gBJu"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
